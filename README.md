# nlp-learning

nlp å…¥é—¨å­¦ä¹ 

# ğŸ’¾å­¦ä¹ èµ„æ–™

https://github.com/graykode/nlp-tutorial

# ğŸ«å­¦ä¹ è®¡åˆ’

| ä¸»é¢˜ |  å†…å®¹|å­¦ä¹ å¤©æ•° | è¿›å±• | æ—¶é—´ç‚¹ |
| --- | --- |--- | --- | --- |
|Basic Embedding Model  |NNLM | 1.5 |  |  |
| Basic Embedding Model | word2vec | 1.5 |  |  ||
| Basic Embedding Model |  fasttext| 2 |  |  ||
|CNN| TextCNN| 2|
|RNN| TextRNN| 2|
|RNN|TextLSTM|1.5|
|RNN|Bi-LSTM |1.5|
|Attention Mechanism| Seq2Seq |2|
|Attention Mechanism| Seq2Seq with Attention|2|
|Bi-LSTM with Attention | Bi_LSTM(Attention)|0.5|
| Model based on Transformer| The Transformer|2|
| Model based on Transformer| bert|2|


# ğŸ˜Šå­¦ä¹ æ•ˆæœæ£€éªŒ

- model å­¦ä¹ ç¬”è®°
- model åº”ç”¨ç»“æœ

# ğŸ˜„å­¦ä¹ å‚è€ƒææ–™
- [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter10_natural-language-processing/10.1_word2vec)
- [cs224n](https://www.bilibili.com/video/BV1pt411h7aT?p=2)

# ğŸš—å†™åœ¨æœ€å
- ç¬”è®°+å®è·µ

